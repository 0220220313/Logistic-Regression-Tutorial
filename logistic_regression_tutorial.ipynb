{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Tutorial\n",
    "---\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression), logistic regression is widely used for binary classification (in economics, discrete choice). Logistic regression was developed by statistician David Cox in 1958. The binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). It allows one to say that the presence of a risk factor increases the odds of a given outcome by a specific factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "---\n",
    "Import packages to make most of the third-party functions work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "# set matplotlib output will show in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import basic package\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset for learning\n",
    "---\n",
    "Let us generate some points to test our simple logistic regression work. The points are stored in a list and later will be converted to numpy array using `np.array`. Each element in the list is a tuple combined by points position (in X, Y) and its label (in binary). For example, point at position (-0.4, 0.3) is categorized in label \"0\" will be entered as element by a tuple variable: `((-0.4, 0.3), 0)`. You can easily imagine that the element here is an instance of the whole dataset, which has two features and labeled by \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array([\n",
    "((-0.4, 0.3), 0),\n",
    "((-0.3, -0.1), 0),\n",
    "((-0.2, 0.4), 0),\n",
    "((-0.1, 0.1), 0),\n",
    "((0.6, -0.5), 0), #非線性分割點\n",
    "\n",
    "((0.8, 0.7), 1),\n",
    "((0.9, -0.5), 1),\n",
    "((0.7, -0.9), 1),\n",
    "((0.8, 0.2), 1),\n",
    "((0.4, -0.6), 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability function\n",
    "---\n",
    "Logistic regression is similar to linear regression, but when tuning weights for each input value (a.k.a. X), the output (a.k.a. Y) will be in binary format. To make regression value normalized to the range between binary (such as 0 and 1), a probability function will be applied on each output to get normalized value, which the equation frequently used is the **sigmoid** function, shows in below:\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "Now the practice begin :) **Complete the following blank part of the code by the sigmoid function above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z)) # this line will be blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "---\n",
    "Now, according to [Wikipedia](https://en.wikipedia.org/wiki/Loss_function), in mathematical optimization, statistics, machine learning and computational neuroscience, a loss function or cost function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. An optimization problem seeks to minimize a loss function. The loss function here we used is basic, achieved by the following equation:\n",
    "$$\\sum( | y-\\sigma(w^T \\cdot x) | )$$\n",
    "Where $y$ is the answer from the dataset of the given input point, $w^T \\cdot x$ is the output value by learned weight and input, by applied $\\sigma$ is to normalize the value into a range (this case is 0 and 1). Note that the $\\sum$ here is to accumulate each input's loss (a.k.a. cost) for later use to get the amount of gradient descent.\n",
    "Practice time :) **Complete the calculation of `error` with correct input for sigmoid and complete the loss calculation in the next line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(dataset, w):\n",
    "    total_cost = 0\n",
    "    for x,y in dataset:\n",
    "        x = np.array(x)\n",
    "        error = sigmoid(w.T.dot(x)) # this line will be blank\n",
    "        total_cost += abs(y - error) # this line will be blank\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descend\n",
    "---\n",
    "After we got the result from the loss function, in machine learning, the core method is to calculate how to adjust weights based on the derived loss, the widely used method is **gradient descend**. According to the loss function, simply by differential the loss function to get its gradient descend function, shows in the following equation:\n",
    "$$G(x,y,w)=(\\sigma(w^T \\cdot x) - y) * x$$\n",
    "Now, practice time again :) **Based on the above equation, fill the blank part in the following code to get predicted value and gradient descend.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(dataset, w):\n",
    "    g = np.zeros(len(w))\n",
    "    for x,y in dataset:\n",
    "        x = np.array(x)\n",
    "        error = sigmoid(w.T.dot(x)) # this line will be blank\n",
    "        g += (error - y) * x # this line will be blank\n",
    "    return g / len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression main function\n",
    "---\n",
    "We have gathered the essential functions for logistic regression, now we are going to combine them and make them work together to achieve what logistic regression does. In each iteration, the cost of each weight resulted will be calculated, then the algorithm will call gradient function to determine what direction should move, by applying the ratio that how gradient will be applied (a.k.a. learning rate, eta), the new weight will be calculated. To optimize the learning rate, after each iteration will make it smaller. To update the weights, following equation will be applied to combine cost, gradient and learning rate.\n",
    "$$w_{t+1}=w_t-\\eta * G(x,y,w)$$\n",
    "Okay, practice time again! **Based on the above equation that updates weights via gradient, fill the blank part of the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0: current_cost= 5.0\n",
      "epoch= 1: current_cost= 4.779324992618724\n",
      "epoch= 2: current_cost= 4.592325118679643\n",
      "epoch= 3: current_cost= 4.433784172346616\n",
      "epoch= 4: current_cost= 4.2988429404745006\n",
      "epoch= 5: current_cost= 4.183335692123967\n",
      "epoch= 6: current_cost= 4.083829185998179\n",
      "epoch= 7: current_cost= 3.997544238504702\n",
      "epoch= 8: current_cost= 3.922245734051402\n",
      "epoch= 9: current_cost= 3.8561364373975593\n",
      "epoch= 10: current_cost= 3.797766345396848\n",
      "epoch= 11: current_cost= 3.7459593853048343\n",
      "epoch= 12: current_cost= 3.699755636442656\n",
      "epoch= 13: current_cost= 3.658366302645526\n",
      "epoch= 14: current_cost= 3.621138749186363\n",
      "epoch= 15: current_cost= 3.5875293334969207\n",
      "epoch= 16: current_cost= 3.5570822212990123\n",
      "epoch= 17: current_cost= 3.5294127890234948\n",
      "epoch= 18: current_cost= 3.504194545083119\n",
      "epoch= 19: current_cost= 3.481148760359043\n",
      "epoch= 20: current_cost= 3.460036194458772\n",
      "epoch= 21: current_cost= 3.4406504521226635\n",
      "epoch= 22: current_cost= 3.4228126150954257\n",
      "epoch= 23: current_cost= 3.4063668780283987\n",
      "epoch= 24: current_cost= 3.3911769795858944\n",
      "epoch= 25: current_cost= 3.377123267184753\n",
      "epoch= 26: current_cost= 3.364100269627837\n",
      "epoch= 27: current_cost= 3.352014679200705\n",
      "epoch= 28: current_cost= 3.340783665727156\n",
      "epoch= 29: current_cost= 3.330333461205148\n",
      "epoch= 30: current_cost= 3.3205981661416284\n",
      "epoch= 31: current_cost= 3.311518738444283\n",
      "epoch= 32: current_cost= 3.303042133360836\n",
      "epoch= 33: current_cost= 3.295120568970827\n",
      "epoch= 34: current_cost= 3.2877108964990107\n",
      "epoch= 35: current_cost= 3.2807740585131815\n",
      "epoch= 36: current_cost= 3.2742746211051332\n",
      "epoch= 37: current_cost= 3.2681803685947868\n",
      "epoch= 38: current_cost= 3.2624619512700574\n",
      "epoch= 39: current_cost= 3.257092578275882\n",
      "epoch= 40: current_cost= 3.2520477490708606\n",
      "epoch= 41: current_cost= 3.2473050179382725\n",
      "epoch= 42: current_cost= 3.242843786916334\n",
      "epoch= 43: current_cost= 3.2386451232372098\n",
      "epoch= 44: current_cost= 3.2346915979645057\n",
      "epoch= 45: current_cost= 3.2309671430180016\n",
      "epoch= 46: current_cost= 3.227456924190712\n",
      "epoch= 47: current_cost= 3.2241472281118955\n",
      "epoch= 48: current_cost= 3.221025361402387\n",
      "epoch= 49: current_cost= 3.2180795605152737\n",
      "epoch= 50: current_cost= 3.2152989109633907\n",
      "epoch= 51: current_cost= 3.2126732748118596\n",
      "epoch= 52: current_cost= 3.2101932254640415\n",
      "epoch= 53: current_cost= 3.207849988897414\n",
      "epoch= 54: current_cost= 3.2056353906152544\n",
      "epoch= 55: current_cost= 3.2035418076738633\n",
      "epoch= 56: current_cost= 3.2015621252255815\n",
      "epoch= 57: current_cost= 3.1996896970873054\n",
      "epoch= 58: current_cost= 3.1979183099040225\n",
      "epoch= 59: current_cost= 3.1962421505287875\n",
      "epoch= 60: current_cost= 3.194655776285417\n",
      "epoch= 61: current_cost= 3.1931540878192624\n",
      "epoch= 62: current_cost= 3.1917323042753907\n",
      "epoch= 63: current_cost= 3.19038594057317\n",
      "epoch= 64: current_cost= 3.1891107865721597\n",
      "epoch= 65: current_cost= 3.1879028879469318\n",
      "epoch= 66: current_cost= 3.186758528608354\n",
      "epoch= 67: current_cost= 3.185674214526374\n",
      "epoch= 68: current_cost= 3.184646658824774\n",
      "epoch= 69: current_cost= 3.1836727680319554\n",
      "epoch= 70: current_cost= 3.1827496293838147\n",
      "epoch= 71: current_cost= 3.181874499085435\n",
      "epoch= 72: current_cost= 3.1810447914477\n",
      "epoch= 73: current_cost= 3.1802580688233353\n",
      "epoch= 74: current_cost= 3.179512032274291\n",
      "epoch= 75: current_cost= 3.178804512909009\n",
      "epoch= 76: current_cost= 3.1781334638340306\n",
      "epoch= 77: current_cost= 3.177496952669629\n",
      "epoch= 78: current_cost= 3.1768931545839356\n",
      "epoch= 79: current_cost= 3.1763203458041356\n",
      "epoch= 80: current_cost= 3.175776897567213\n",
      "epoch= 81: current_cost= 3.1752612704760104\n",
      "epoch= 82: current_cost= 3.1747720092294838\n",
      "epoch= 83: current_cost= 3.1743077376987525\n",
      "epoch= 84: current_cost= 3.173867154323005\n",
      "epoch= 85: current_cost= 3.173449027801583\n",
      "epoch= 86: current_cost= 3.1730521930605438\n",
      "epoch= 87: current_cost= 3.172675547473844\n",
      "epoch= 88: current_cost= 3.172318047320927\n",
      "epoch= 89: current_cost= 3.1719787044639927\n",
      "epoch= 90: current_cost= 3.171656583229578\n",
      "epoch= 91: current_cost= 3.1713507974803115\n",
      "epoch= 92: current_cost= 3.1710605078638276\n",
      "epoch= 93: current_cost= 3.170784919226829\n",
      "epoch= 94: current_cost= 3.1705232781832335\n",
      "epoch= 95: current_cost= 3.170274870826175\n",
      "epoch= 96: current_cost= 3.170039020574403\n",
      "epoch= 97: current_cost= 3.1698150861443373\n",
      "epoch= 98: current_cost= 3.169602459639669\n",
      "epoch= 99: current_cost= 3.1694005647510104\n"
     ]
    }
   ],
   "source": [
    "def logistic(dataset):\n",
    "    w = np.zeros(len(dataset[0][0]))\n",
    "\n",
    "    limit = 100 #更新十次後停下\n",
    "\n",
    "    eta = 1 #更新幅度\n",
    "\n",
    "    costs = [] #紀錄每次更新權重後新的cost是多少\n",
    "\n",
    "    for i in range(limit):\n",
    "        current_cost = cost(dataset, w)\n",
    "        print \"epoch= \"+str(i)+\": current_cost=\",current_cost\n",
    "        costs.append(current_cost)\n",
    "        w = w - eta * gradient(dataset, w)\n",
    "        eta *= 0.95 #更新幅度，逐步遞減\n",
    "        \n",
    "    return w,(limit,costs)\n",
    "\n",
    "# implement logistic class and run it\n",
    "w = logistic(dataset)\n",
    "limit = w[1][0]\n",
    "costs = w[1][1]\n",
    "w = w[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "---\n",
    "Great! Here shows your implementation of logistic regression's cost performance after each iteration on learning the simple dataset. Also in the next block will show the learned linear line that best separates the given point into two class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10be18150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show loss curve\n",
    "\n",
    "plt.plot(range(limit), costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bed7110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show result\n",
    "\n",
    "ps = [v[0] for v in dataset]\n",
    "label = [v[1] for v in dataset]\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# plot via label\n",
    "for idx,Label in enumerate(label):\n",
    "    if Label==1:\n",
    "        ax1.scatter(ps[idx][0],ps[idx][1], s=10, c='b', marker=\"o\", label='O')\n",
    "    else:\n",
    "        ax1.scatter(ps[idx][0],ps[idx][1], s=10, c='r', marker=\"x\", label='X')\n",
    "\n",
    "l = np.linspace(-2,2)\n",
    "a,b = w[0]/w[1], w[0]\n",
    "ax1.plot(l, a*l + b, 'b-')\n",
    "#plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "> http://terrence.logdown.com/posts/440690-python-super-simple-implementation-of-logistic-regression-classification-and-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
